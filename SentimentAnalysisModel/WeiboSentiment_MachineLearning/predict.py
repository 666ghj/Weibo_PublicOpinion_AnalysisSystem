# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€çš„æƒ…æ„Ÿåˆ†æé¢„æµ‹ç¨‹åº
æ”¯æŒåŠ è½½æ‰€æœ‰æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹
"""
import argparse
import os
import re
from typing import Dict, Tuple, List
import warnings
warnings.filterwarnings("ignore")

# å¯¼å…¥æ‰€æœ‰æ¨¡å‹ç±»
from bayes_train import BayesModel
from svm_train import SVMModel
from xgboost_train import XGBoostModel
from lstm_train import LSTMModel
from bert_train import BertModel_Custom
from utils import processing


class SentimentPredictor:
    """æƒ…æ„Ÿåˆ†æé¢„æµ‹å™¨"""
    
    def __init__(self):
        self.models = {}
        self.available_models = {
            'bayes': BayesModel,
            'svm': SVMModel,
            'xgboost': XGBoostModel,
            'lstm': LSTMModel,
            'bert': BertModel_Custom
        }
        
    def load_model(self, model_type: str, model_path: str, **kwargs) -> None:
        """åŠ è½½æŒ‡å®šç±»å‹çš„æ¨¡å‹
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ('bayes', 'svm', 'xgboost', 'lstm', 'bert')
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆå¦‚BERTçš„é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼‰
        """
        if model_type not in self.available_models:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
        
        if not os.path.exists(model_path):
            print(f"è­¦å‘Š: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return
        
        print(f"åŠ è½½ {model_type.upper()} æ¨¡å‹...")
        
        try:
            if model_type == 'bert':
                # BERTéœ€è¦é¢å¤–çš„é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
                bert_path = kwargs.get('bert_path', './model/chinese_wwm_pytorch')
                model = BertModel_Custom(bert_path)
            else:
                model = self.available_models[model_type]()
            
            model.load_model(model_path)
            self.models[model_type] = model
            print(f"{model_type.upper()} æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"åŠ è½½ {model_type.upper()} æ¨¡å‹å¤±è´¥: {e}")
    
    def load_all_models(self, model_dir: str = './model', bert_path: str = './model/chinese_wwm_pytorch') -> None:
        """åŠ è½½æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
        
        Args:
            model_dir: æ¨¡å‹æ–‡ä»¶ç›®å½•
            bert_path: BERTé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        """
        model_files = {
            'bayes': os.path.join(model_dir, 'bayes_model.pkl'),
            'svm': os.path.join(model_dir, 'svm_model.pkl'),
            'xgboost': os.path.join(model_dir, 'xgboost_model.pkl'),
            'lstm': os.path.join(model_dir, 'lstm_model.pth'),
            'bert': os.path.join(model_dir, 'bert_model.pth')
        }
        
        print("å¼€å§‹åŠ è½½æ‰€æœ‰å¯ç”¨æ¨¡å‹...")
        for model_type, model_path in model_files.items():
            self.load_model(model_type, model_path, bert_path=bert_path)
        
        print(f"\nå·²åŠ è½½ {len(self.models)} ä¸ªæ¨¡å‹: {list(self.models.keys())}")
    
    def predict_single(self, text: str, model_type: str = None) -> Dict[str, Tuple[int, float]]:
        """é¢„æµ‹å•æ¡æ–‡æœ¬çš„æƒ…æ„Ÿ
        
        Args:
            text: å¾…é¢„æµ‹æ–‡æœ¬
            model_type: æŒ‡å®šæ¨¡å‹ç±»å‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰å·²åŠ è½½çš„æ¨¡å‹
            
        Returns:
            Dict[model_type, (prediction, confidence)]
        """
        # æ–‡æœ¬é¢„å¤„ç†
        processed_text = processing(text)
        
        if model_type:
            if model_type not in self.models:
                raise ValueError(f"æ¨¡å‹ {model_type} æœªåŠ è½½")
            
            prediction, confidence = self.models[model_type].predict_single(processed_text)
            return {model_type: (prediction, confidence)}
        
        # ä½¿ç”¨æ‰€æœ‰æ¨¡å‹é¢„æµ‹
        results = {}
        for name, model in self.models.items():
            try:
                prediction, confidence = model.predict_single(processed_text)
                results[name] = (prediction, confidence)
            except Exception as e:
                print(f"æ¨¡å‹ {name} é¢„æµ‹å¤±è´¥: {e}")
                results[name] = (0, 0.0)
        
        return results
    
    def predict_batch(self, texts: List[str], model_type: str = None) -> Dict[str, List[int]]:
        """æ‰¹é‡é¢„æµ‹æ–‡æœ¬æƒ…æ„Ÿ
        
        Args:
            texts: å¾…é¢„æµ‹æ–‡æœ¬åˆ—è¡¨
            model_type: æŒ‡å®šæ¨¡å‹ç±»å‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰å·²åŠ è½½çš„æ¨¡å‹
            
        Returns:
            Dict[model_type, predictions]
        """
        # æ–‡æœ¬é¢„å¤„ç†
        processed_texts = [processing(text) for text in texts]
        
        if model_type:
            if model_type not in self.models:
                raise ValueError(f"æ¨¡å‹ {model_type} æœªåŠ è½½")
            
            predictions = self.models[model_type].predict(processed_texts)
            return {model_type: predictions}
        
        # ä½¿ç”¨æ‰€æœ‰æ¨¡å‹é¢„æµ‹
        results = {}
        for name, model in self.models.items():
            try:
                predictions = model.predict(processed_texts)
                results[name] = predictions
            except Exception as e:
                print(f"æ¨¡å‹ {name} é¢„æµ‹å¤±è´¥: {e}")
                results[name] = [0] * len(texts)
        
        return results
    
    def ensemble_predict(self, text: str, weights: Dict[str, float] = None) -> Tuple[int, float]:
        """é›†æˆé¢„æµ‹ï¼ˆå¤šä¸ªæ¨¡å‹æŠ•ç¥¨ï¼‰
        
        Args:
            text: å¾…é¢„æµ‹æ–‡æœ¬
            weights: æ¨¡å‹æƒé‡ï¼Œå¦‚æœä¸ºNoneåˆ™å¹³å‡æƒé‡
            
        Returns:
            (prediction, confidence)
        """
        if len(self.models) == 0:
            raise ValueError("æ²¡æœ‰åŠ è½½ä»»ä½•æ¨¡å‹")
        
        results = self.predict_single(text)
        
        if weights is None:
            weights = {name: 1.0 for name in results.keys()}
        
        # åŠ æƒå¹³å‡
        total_weight = 0
        weighted_prob = 0
        
        for model_name, (pred, conf) in results.items():
            if model_name in weights:
                weight = weights[model_name]
                prob = conf if pred == 1 else 1 - conf
                weighted_prob += prob * weight
                total_weight += weight
        
        if total_weight == 0:
            return 0, 0.5
        
        final_prob = weighted_prob / total_weight
        final_pred = int(final_prob > 0.5)
        final_conf = final_prob if final_pred == 1 else 1 - final_prob
        
        return final_pred, final_conf
    
    def interactive_predict(self):
        """äº¤äº’å¼é¢„æµ‹æ¨¡å¼"""
        if len(self.models) == 0:
            print("é”™è¯¯: æ²¡æœ‰åŠ è½½ä»»ä½•æ¨¡å‹ï¼Œè¯·å…ˆåŠ è½½æ¨¡å‹")
            return
        
        print("\n" + "="*50)
        print("="*50)
        print(f"å·²åŠ è½½æ¨¡å‹: {', '.join(self.models.keys())}")
        print("è¾“å…¥ 'q' é€€å‡ºç¨‹åº")
        print("è¾“å…¥ 'models' æŸ¥çœ‹æ¨¡å‹åˆ—è¡¨")
        print("è¾“å…¥ 'ensemble' ä½¿ç”¨é›†æˆé¢„æµ‹")
        print("-"*50)
        
        while True:
            try:
                text = input("\nè¯·è¾“å…¥è¦åˆ†æçš„å¾®åšå†…å®¹: ").strip()
                
                if text.lower() == 'q':
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                if text.lower() == 'models':
                    print(f"å·²åŠ è½½æ¨¡å‹: {list(self.models.keys())}")
                    continue
                
                if text.lower() == 'ensemble':
                    if len(self.models) > 1:
                        pred, conf = self.ensemble_predict(text)
                        sentiment = "ğŸ˜Š æ­£é¢" if pred == 1 else "ğŸ˜ è´Ÿé¢"
                        print(f"\nğŸ¤– é›†æˆé¢„æµ‹ç»“æœ:")
                        print(f"   æƒ…æ„Ÿå€¾å‘: {sentiment}")
                        print(f"   ç½®ä¿¡åº¦: {conf:.4f}")
                    else:
                        print("âŒ é›†æˆé¢„æµ‹éœ€è¦è‡³å°‘2ä¸ªæ¨¡å‹")
                    continue
                
                if not text:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                    continue
                
                # é¢„æµ‹
                results = self.predict_single(text)
                
                print(f"\nğŸ“ åŸæ–‡: {text}")
                print("ğŸ” é¢„æµ‹ç»“æœ:")
                
                for model_name, (pred, conf) in results.items():
                    sentiment = "ğŸ˜Š æ­£é¢" if pred == 1 else "ğŸ˜ è´Ÿé¢"
                    print(f"   {model_name.upper():8}: {sentiment} (ç½®ä¿¡åº¦: {conf:.4f})")
                
                # å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œæ˜¾ç¤ºé›†æˆç»“æœ
                if len(results) > 1:
                    ensemble_pred, ensemble_conf = self.ensemble_predict(text)
                    ensemble_sentiment = "ğŸ˜Š æ­£é¢" if ensemble_pred == 1 else "ğŸ˜ è´Ÿé¢"
                    print(f"   {'é›†æˆ':8}: {ensemble_sentiment} (ç½®ä¿¡åº¦: {ensemble_conf:.4f})")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¾®åšæƒ…æ„Ÿåˆ†æç»Ÿä¸€é¢„æµ‹ç¨‹åº')
    parser.add_argument('--model_dir', type=str, default='./model',
                        help='æ¨¡å‹æ–‡ä»¶ç›®å½•')
    parser.add_argument('--bert_path', type=str, default='./model/chinese_wwm_pytorch',
                        help='BERTé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--model_type', type=str, choices=['bayes', 'svm', 'xgboost', 'lstm', 'bert'],
                        help='æŒ‡å®šå•ä¸ªæ¨¡å‹ç±»å‹è¿›è¡Œé¢„æµ‹')
    parser.add_argument('--text', type=str,
                        help='ç›´æ¥é¢„æµ‹æŒ‡å®šæ–‡æœ¬')
    parser.add_argument('--interactive', action='store_true', default=True,
                        help='äº¤äº’å¼é¢„æµ‹æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰')
    parser.add_argument('--ensemble', action='store_true',
                        help='ä½¿ç”¨é›†æˆé¢„æµ‹')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = SentimentPredictor()
    
    # åŠ è½½æ¨¡å‹
    if args.model_type:
        # åŠ è½½æŒ‡å®šæ¨¡å‹
        model_files = {
            'bayes': 'bayes_model.pkl',
            'svm': 'svm_model.pkl',
            'xgboost': 'xgboost_model.pkl',
            'lstm': 'lstm_model.pth',
            'bert': 'bert_model.pth'
        }
        model_path = os.path.join(args.model_dir, model_files[args.model_type])
        predictor.load_model(args.model_type, model_path, bert_path=args.bert_path)
    else:
        # åŠ è½½æ‰€æœ‰æ¨¡å‹
        predictor.load_all_models(args.model_dir, args.bert_path)
    
    # å¦‚æœæŒ‡å®šäº†æ–‡æœ¬ï¼Œç›´æ¥é¢„æµ‹
    if args.text:
        if args.ensemble and len(predictor.models) > 1:
            pred, conf = predictor.ensemble_predict(args.text)
            sentiment = "æ­£é¢" if pred == 1 else "è´Ÿé¢"
            print(f"æ–‡æœ¬: {args.text}")
            print(f"é›†æˆé¢„æµ‹: {sentiment} (ç½®ä¿¡åº¦: {conf:.4f})")
        else:
            results = predictor.predict_single(args.text, args.model_type)
            print(f"æ–‡æœ¬: {args.text}")
            for model_name, (pred, conf) in results.items():
                sentiment = "æ­£é¢" if pred == 1 else "è´Ÿé¢"
                print(f"{model_name.upper()}: {sentiment} (ç½®ä¿¡åº¦: {conf:.4f})")
    elif args.interactive:
        # äº¤äº’å¼æ¨¡å¼
        predictor.interactive_predict()


if __name__ == "__main__":
    main()