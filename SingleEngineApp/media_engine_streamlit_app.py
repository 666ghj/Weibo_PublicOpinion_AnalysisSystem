"""
Streamlit Webç•Œé¢
ä¸ºMedia Agentæä¾›å‹å¥½çš„Webç•Œé¢
"""

import os
import sys
import streamlit as st
from datetime import datetime
import json

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from MediaEngine import DeepSearchAgent, Config
from config import DEEPSEEK_API_KEY, BOCHA_Web_Search_API_KEY, GEMINI_API_KEY


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="Media Agent",
        page_icon="ðŸ”",
        layout="wide"
    )

    st.title("Media Agent")
    st.markdown("å…·å¤‡å¼ºå¤§å¤šæ¨¡æ€èƒ½åŠ›çš„AIä»£ç†")

    # æ£€æŸ¥URLå‚æ•°
    try:
        # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬çš„query_params
        query_params = st.query_params
        auto_query = query_params.get('query', '')
        auto_search = query_params.get('auto_search', 'false').lower() == 'true'
    except AttributeError:
        # å…¼å®¹æ—§ç‰ˆæœ¬
        query_params = st.experimental_get_query_params()
        auto_query = query_params.get('query', [''])[0]
        auto_search = query_params.get('auto_search', ['false'])[0].lower() == 'true'

    # ----- é…ç½®è¢«ç¡¬ç¼–ç  -----
    # å¼ºåˆ¶ä½¿ç”¨ Gemini
    llm_provider = "gemini"
    model_name = "gemini-2.5-pro"
    # é»˜è®¤é«˜çº§é…ç½®
    max_reflections = 2
    max_content_length = 20000

    # ä¸»ç•Œé¢
    col1, col2 = st.columns([2, 1])

    with col1:
        st.header("ç ”ç©¶æŸ¥è¯¢")
        
        # å¦‚æžœæœ‰è‡ªåŠ¨æŸ¥è¯¢ï¼Œä½¿ç”¨å®ƒä½œä¸ºé»˜è®¤å€¼
        default_query = auto_query if auto_query else ""
        
        query = st.text_area(
            "è¯·è¾“å…¥æ‚¨è¦ç ”ç©¶çš„é—®é¢˜",
            value=default_query,
            placeholder="ä¾‹å¦‚ï¼š2025å¹´äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
            height=100
        )

    with col2:
        st.header("çŠ¶æ€ä¿¡æ¯")
        if 'agent' in st.session_state and hasattr(st.session_state.agent, 'state'):
            progress = st.session_state.agent.get_progress_summary()
            st.metric("æ€»æ®µè½æ•°", progress['total_paragraphs'])
            st.metric("å·²å®Œæˆ", progress['completed_paragraphs'])
            st.progress(progress['progress_percentage'] / 100)
        else:
            st.info("å°šæœªå¼€å§‹ç ”ç©¶")

    # æ‰§è¡ŒæŒ‰é’®
    col1_btn, col2_btn, col3_btn = st.columns([1, 1, 1])
    with col2_btn:
        start_research = st.button("å¼€å§‹ç ”ç©¶", type="primary", use_container_width=True)
    
    # è‡ªåŠ¨æœç´¢é€»è¾‘
    if auto_search and auto_query and 'auto_search_executed' not in st.session_state:
        st.session_state.auto_search_executed = True
        start_research = True
        query = auto_query

    # éªŒè¯é…ç½®
    if start_research:
        if not query.strip():
            st.error("è¯·è¾“å…¥ç ”ç©¶æŸ¥è¯¢")
            return

        # ç”±äºŽå¼ºåˆ¶ä½¿ç”¨Geminiï¼Œæ£€æŸ¥ç›¸å…³çš„APIå¯†é’¥
        if not GEMINI_API_KEY:
            st.error("è¯·åœ¨æ‚¨çš„é…ç½®æ–‡ä»¶(config.py)ä¸­è®¾ç½®GEMINI_API_KEY")
            return
        if not BOCHA_Web_Search_API_KEY:
            st.error("è¯·åœ¨æ‚¨çš„é…ç½®æ–‡ä»¶(config.py)ä¸­è®¾ç½®BOCHA_Web_Search_API_KEY")
            return

        # è‡ªåŠ¨ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥
        gemini_key = GEMINI_API_KEY
        bocha_key = BOCHA_Web_Search_API_KEY

        # åˆ›å»ºé…ç½®
        config = Config(
            deepseek_api_key=None,
            openai_api_key=None,
            gemini_api_key=gemini_key,
            bocha_api_key=bocha_key,
            default_llm_provider=llm_provider,
            deepseek_model="deepseek-chat",  # ä¿ç•™é»˜è®¤å€¼ä»¥å…¼å®¹
            openai_model="gpt-4o-mini",  # ä¿ç•™é»˜è®¤å€¼ä»¥å…¼å®¹
            gemini_model=model_name,
            max_reflections=max_reflections,
            max_content_length=max_content_length,
            output_dir="media_engine_streamlit_reports"
        )

        # æ‰§è¡Œç ”ç©¶
        execute_research(query, config)


def execute_research(query: str, config: Config):
    """æ‰§è¡Œç ”ç©¶"""
    try:
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()

        # åˆå§‹åŒ–Agent
        status_text.text("æ­£åœ¨åˆå§‹åŒ–Agent...")
        agent = DeepSearchAgent(config)
        st.session_state.agent = agent

        progress_bar.progress(10)

        # ç”ŸæˆæŠ¥å‘Šç»“æž„
        status_text.text("æ­£åœ¨ç”ŸæˆæŠ¥å‘Šç»“æž„...")
        agent._generate_report_structure(query)
        progress_bar.progress(20)

        # å¤„ç†æ®µè½
        total_paragraphs = len(agent.state.paragraphs)
        for i in range(total_paragraphs):
            status_text.text(f"æ­£åœ¨å¤„ç†æ®µè½ {i + 1}/{total_paragraphs}: {agent.state.paragraphs[i].title}")

            # åˆå§‹æœç´¢å’Œæ€»ç»“
            agent._initial_search_and_summary(i)
            progress_value = 20 + (i + 0.5) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

            # åæ€å¾ªçŽ¯
            agent._reflection_loop(i)
            agent.state.paragraphs[i].research.mark_completed()

            progress_value = 20 + (i + 1) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        status_text.text("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        final_report = agent._generate_final_report()
        progress_bar.progress(90)

        # ä¿å­˜æŠ¥å‘Š
        status_text.text("æ­£åœ¨ä¿å­˜æŠ¥å‘Š...")
        agent._save_report(final_report)
        progress_bar.progress(100)

        status_text.text("ç ”ç©¶å®Œæˆï¼")

        # æ˜¾ç¤ºç»“æžœ
        display_results(agent, final_report)

    except Exception as e:
        st.error(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


def display_results(agent: DeepSearchAgent, final_report: str):
    """æ˜¾ç¤ºç ”ç©¶ç»“æžœ"""
    st.header("ç ”ç©¶ç»“æžœ")

    # ç»“æžœæ ‡ç­¾é¡µï¼ˆå·²ç§»é™¤ä¸‹è½½é€‰é¡¹ï¼‰
    tab1, tab2 = st.tabs(["æœ€ç»ˆæŠ¥å‘Š", "è¯¦ç»†ä¿¡æ¯"])

    with tab1:
        st.markdown(final_report)

    with tab2:
        # æ®µè½è¯¦æƒ…
        st.subheader("æ®µè½è¯¦æƒ…")
        for i, paragraph in enumerate(agent.state.paragraphs):
            with st.expander(f"æ®µè½ {i + 1}: {paragraph.title}"):
                st.write("**é¢„æœŸå†…å®¹:**", paragraph.content)
                st.write("**æœ€ç»ˆå†…å®¹:**", paragraph.research.latest_summary[:300] + "..."
                if len(paragraph.research.latest_summary) > 300
                else paragraph.research.latest_summary)
                st.write("**æœç´¢æ¬¡æ•°:**", paragraph.research.get_search_count())
                st.write("**åæ€æ¬¡æ•°:**", paragraph.research.reflection_iteration)

        # æœç´¢åŽ†å²
        st.subheader("æœç´¢åŽ†å²")
        all_searches = []
        for paragraph in agent.state.paragraphs:
            all_searches.extend(paragraph.research.search_history)

        if all_searches:
            for i, search in enumerate(all_searches):
                with st.expander(f"æœç´¢ {i + 1}: {search.query}"):
                    st.write("**URL:**", search.url)
                    st.write("**æ ‡é¢˜:**", search.title)
                    st.write("**å†…å®¹é¢„è§ˆ:**",
                             search.content[:200] + "..." if len(search.content) > 200 else search.content)
                    if search.score:
                        st.write("**ç›¸å…³åº¦è¯„åˆ†:**", search.score)


if __name__ == "__main__":
    main()